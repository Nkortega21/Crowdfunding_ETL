# Crowdfunding_ETL
UCI Data Analyst Project 2 - ETL mini project

For this project we worked as a group with Brendan Golden, Nick Ortega, Chris Rahal, and Wei Wang. As a group we finished all parts of this mini-project and hope to have provided a concise, descriptive implementation of each individual component of the assignment. This project deal with basic ETL concepts and principles, providing an insightful way into data engineering. 

We had to first extract and transform excel and csv files into more productive, and informative databases to be used at a future time. We were required to apply concepts taught to us in class such as creating lists of columns and values and reintegrating them into a readable and understandable data frame. We had to split a category and sub-category column into sub-columns and create subsequent data frames based off our results outlining the unique categories and sub-categories that existed in the provided excel file. Finally, we exported the created data frames into csv files. 

Next the assignment required using integral functions built into Pandas such renaming columns, changing the data types of certain columns using astype and pd to datetime methods, and finally using merge and drop abilities to acquire the final, desired result provided in the starter code, while ultimately exporting the final data frame. 
 The penultimate component of the project involved using json to extract contact information from an excel file and create a viewable dictionary that details the pertinent information from the jumbled file provided. We decided to apply option 1 to achieve the results as we felt more comfortable than using the regex method. We created a for loop that extracts each row from the file, then loads the file using json properties, and finally extract the key and value pairs from the data using a complex list comprehension method, while finally printing out the final desired outcome. In the end we completed the necessary components by creating the data frame based off the required columns, splitting the first and last name columns, dropping unnecessary components, and sorting the columns into a more presentable format and exporting the file. 
 
For the final component of the project we synthesized a workable table schemata for sequel, in which we could import and manipulate the data frames that we created during the jupyter notebook portion of the assignment. We successfully created the four tables using primary, and foreign key methods and correctly applied the necessary constraints to each column of all four tables. We then used QuickDB to outline our work using an ERD which identifies the unique relationships between the tables in our schema. 

All in all, we collectively were able to answer and provide conclusions for each, individual component of the assignment. 
